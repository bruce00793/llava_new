# ğŸš€ è®­ç»ƒå¿«é€Ÿå¼€å§‹ï¼ˆ3åˆ†é’Ÿä¸Šæ‰‹ï¼‰

## æ ¸å¿ƒå‘½ä»¤ï¼ˆå¤åˆ¶ç²˜è´´å³å¯ï¼‰

### 1ï¸âƒ£ ç”ŸæˆGT Cacheï¼ˆåªéœ€è¿è¡Œä¸€æ¬¡ï¼‰

```bash
cd /home/cly/auto/llava_test/LLaVA

# ä¿®æ”¹ä¸‹é¢çš„è·¯å¾„ä¸ºä½ çš„nuScenesè·¯å¾„
DATAROOT="/path/to/nuscenes"
VERSION="v1.0-mini"

# ç”Ÿæˆè®­ç»ƒé›†GT
python tools/generate_gt_cache.py \
    --dataroot "$DATAROOT" \
    --version "$VERSION" \
    --split train \
    --output gt_cache_train.pkl

# ç”ŸæˆéªŒè¯é›†GT
python tools/generate_gt_cache.py \
    --dataroot "$DATAROOT" \
    --version "$VERSION" \
    --split val \
    --output gt_cache_val.pkl
```

### 2ï¸âƒ£ æµ‹è¯•ç¯å¢ƒï¼ˆå¯é€‰ä½†æ¨èï¼‰

```bash
conda activate llava_new
python test_training_setup.py
```

åº”è¯¥çœ‹åˆ°ï¼š`âœ… All core tests passed!`

### 3ï¸âƒ£ ä¿®æ”¹é…ç½®å¹¶å¼€å§‹è®­ç»ƒ

```bash
# ç¼–è¾‘é…ç½®
vim scripts/train_stage2.sh
# åªéœ€ä¿®æ”¹è¿™ä¸€è¡Œï¼š
# DATAROOT="/path/to/nuscenes"  â† æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„

# å¼€å§‹è®­ç»ƒï¼
bash scripts/train_stage2.sh
```

---

## ğŸ¯ é¢„æœŸè¾“å‡º

### è®­ç»ƒå¼€å§‹æ—¶
```
==========================================
LLaVA Map Detection - Stage 2 Training
==========================================
Building model...
ğŸ“¥ Loading BLIP-2 pretrained Q-Former...
âœ… BLIP-2 Q-Former loaded!
âœ… LLM loaded successfully!
âœ… Map Decoder initialized
âœ… LLM frozen, only training:
   - Q-Former
   - Map Queries (1050 learnable queries)
   - Map Decoder

Parameter Groups:
  qformer:     100,234,567 params, lr=1e-05
  queries:       4,300,800 params, lr=1e-04
  decoder:      11,234,567 params, lr=1e-04
==========================================

Starting Training...
```

### è®­ç»ƒè¿‡ç¨‹ä¸­
```
Epoch [1/24] Step [10/200] Loss: 3.5421 (Avg: 3.6234)
LR: q=1.00e-05 m=1.00e-04 d=1.00e-04

Detailed losses:
  loss_cls: 1.2345 (Avg: 1.3456)
  loss_pts: 1.8765 (Avg: 1.9012)
  loss_dir: 0.4311 (Avg: 0.3766)
  loss_total: 3.5421 (Avg: 3.6234)
```

### ä¿å­˜checkpointæ—¶
```
ğŸ’¾ Checkpoint saved to outputs/map_detection_stage2_XXX/checkpoint_epoch_1.pth
```

---

## ğŸ“Š æ˜¾å­˜å‚è€ƒ

| GPUå‹å· | æ¨èBatch Size | æ˜¾å­˜å ç”¨ |
|---------|---------------|---------|
| A100 40GB | 4 | 23GB |
| V100 32GB | 2 | 15GB |
| RTX 3090 24GB | 1 | 10GB |

---

## â“ å¿«é€Ÿé—®é¢˜æ’æŸ¥

### âŒ é—®é¢˜ï¼šOOM (æ˜¾å­˜ä¸è¶³)
```bash
# è§£å†³ï¼šé™ä½batch size
# ç¼–è¾‘ scripts/train_stage2.shï¼Œä¿®æ”¹ï¼š
BATCH_SIZE=2  # æˆ– 1
```

### âŒ é—®é¢˜ï¼šGT Cacheç”Ÿæˆå¤±è´¥
```bash
# æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®
ls /path/to/nuscenes/v1.0-mini/
# åº”è¯¥çœ‹åˆ°ï¼šscene.json, sample.json ç­‰æ–‡ä»¶
```

### âŒ é—®é¢˜ï¼šæ¨¡å—å¯¼å…¥é”™è¯¯
```bash
# ç¡®è®¤ç¯å¢ƒæ¿€æ´»
conda activate llava_new

# ç¡®è®¤åœ¨æ­£ç¡®ç›®å½•
cd /home/cly/auto/llava_test/LLaVA
```

### âŒ é—®é¢˜ï¼šBLIP-2ä¸‹è½½æ…¢/å¤±è´¥
```bash
# ä½¿ç”¨å›½å†…é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–è·³è¿‡BLIP-2ï¼ˆä¸æ¨èï¼Œæ€§èƒ½ä¸‹é™ï¼‰
# ç¼–è¾‘ scripts/train_stage2.shï¼š
--qformer-pretrained none
```

---

## ğŸ“‚ è®­ç»ƒè¾“å‡ºä½ç½®

```
outputs/map_detection_stage2_YYYYMMDD_HHMMSS/
â”œâ”€â”€ best_model.pth           â† ç”¨è¿™ä¸ªåšæ¨ç†ï¼
â”œâ”€â”€ checkpoint_epoch_N.pth
â””â”€â”€ final_model.pth
```

---

## ğŸ“– æ›´å¤šæ–‡æ¡£

- **è¯¦ç»†æ•™ç¨‹**: [TRAINING_GUIDE.md](./TRAINING_GUIDE.md)
- **å®Œæ•´è¯´æ˜**: [STAGE2_TRAINING_README.md](./STAGE2_TRAINING_README.md)
- **ä»£ç æ€»ç»“**: [TRAINING_SUMMARY.md](./TRAINING_SUMMARY.md)

---

## âœ… å‡†å¤‡å¥½äº†å—ï¼Ÿ

```bash
# å¤åˆ¶è¿™äº›å‘½ä»¤ï¼Œä¿®æ”¹è·¯å¾„åè¿è¡Œï¼š

cd /home/cly/auto/llava_test/LLaVA
DATAROOT="/path/to/nuscenes"  # â† ä¿®æ”¹è¿™é‡Œ

# Step 1: ç”ŸæˆGT
python tools/generate_gt_cache.py --dataroot "$DATAROOT" --version v1.0-mini --split train --output gt_cache_train.pkl
python tools/generate_gt_cache.py --dataroot "$DATAROOT" --version v1.0-mini --split val --output gt_cache_val.pkl

# Step 2: æµ‹è¯•
python test_training_setup.py

# Step 3: ä¿®æ”¹å¹¶å¼€å§‹è®­ç»ƒ
vim scripts/train_stage2.sh  # ä¿®æ”¹DATAROOT
bash scripts/train_stage2.sh
```

**å°±æ˜¯è¿™ä¹ˆç®€å•ï¼ğŸ‰**

